# -*- coding: utf-8 -*-
"""DT-Questions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UgcO0QxX4ODebkalyyS_sV_K67hpx3O0

# Problem Statement
The purpose is to predict whether the Pima Indian women shows signs of diabetes or not. We are using a dataset collected by 
"National Institute of Diabetes and Digestive and Kidney Diseases" which consists of a number of attributes which would help us 
to perform this prediction.

Constraints on data collection
All patients whose data has been collected are females at least 21 years old of Pima Indian heritage

# Dataset:
https://www.kaggle.com/kumargh/pimaindiansdiabetescsv

# 1. Import Libraries and load dataset
"""

from google.colab import files
  
uploaded = files.upload()

# Commented out IPython magic to ensure Python compatibility.
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt       # matplotlib.pyplot plots data
# %matplotlib inline 
import seaborn as sns
import io

pima_df = pd.read_csv('pima-indians-diabetes.csv')

"""It is always a good practice to eye-ball raw data to get a feel of the data in terms of number of structure of the file, number 
of attributes, types of attributes and a general idea of likely challenges in the dataset. You would notice that it is a comma 
separated file. There are no column names!. Check the associated folders and find out about each attribute the name. What 
information is available about the data.

# 2. Print 10 samples from the dataset
"""

pima_df.head(10)

"""# 3. Print the datatypes of each column and the shape of the dataset"""

pima_df.shape

pima_df.info()

"""There are '0's in the data. Are they really valid '0's or they are missing values? Plasma, BP, skin thickness etc. these values 
cannot be 0. look at column by column logically to understand this.

# 4. Replace all the 0s in the column with the median of the same column value accordingly.
"""

pima_df.loc[pima_df.Plas == 0, 'Plas'] = pima_df.Plas.median()
pima_df.loc[pima_df.Pres == 0, 'Pres'] = pima_df.Pres.median()
pima_df.loc[pima_df.skin == 0, 'skin'] = pima_df.skin.median()
pima_df.loc[pima_df.test == 0, 'test'] = pima_df.test.median()
pima_df.loc[pima_df.mass == 0, 'mass'] = pima_df.mass.median()

"""# 5. Print the descriptive statistics of each & every column using describe() function"""

pima_df.describe()

"""# 6. See the distribution of 'Class' variable and plot it using appropriate graph"""

pima_df.groupby("class").agg({'class': 'count'})

"""# 7. Use pairplots and correlation method to observe the relationship between different variables and state your insights.
Hint: Use seaborn plot and check the relationship between different variables
"""

import seaborn as sns
sns.pairplot(pima_df, hue="class", palette="husl")

pima_df.corr()

"""Check for correlation between variables whose values are >0.8

# 8. Split the pima_df into training and test set in the ratio of 70:30 (Training:Test).
"""

# splitting data into training and test set for independent attributes
n=pima_df['class'].count()
train_set = pima_df.head(int(round(n*0.7))) # Up to the last initial training set row
test_set = pima_df.tail(int(round(n*0.3))) # Past the last initial training set row

# capture the target column ("class") into separate vectors for training set and test set
train_labels = train_set.pop("class")
test_labels = test_set.pop("class")

"""# 9. Create the decision tree model using “entropy” method of reducing the entropy and fit it to training data."""

from sklearn.tree import DecisionTreeClassifier
dt_model = DecisionTreeClassifier(criterion = 'entropy' )
dt_model.fit(train_set, train_labels)

"""# 10. Print the accuracy of the model & print the confusion matrix"""

dt_model.score(test_set , test_labels)

test_pred = dt_model.predict(test_set)

print (pd.DataFrame(dt_model.feature_importances_, columns = ["Imp"], index = train_set.columns))

